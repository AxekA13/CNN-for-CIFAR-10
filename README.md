# CNN-for-CIFAR-10

Этот проект создан для лабораторной работы №1 (Simple CNN for CIFAR-10 dataset) по курсу Deep Learning
## Описание модели
Данная модель представляет собой Свёрточную нейронную сеть, суть которой заключается в применении операции свёртки к исходному изображению.
Сверточные сети отличаются очень высокой способностью к распознаванию паттернов на изображениях, поэтому их чаще всего применяют в работах с доменами, связанными с обработкой изображений.

* Свертка

Сверточные нейронные сети работают на основе фильтров, которые занимаются распознаванием определенных характеристик изображения (например, прямых линий). Фильтр — это коллекция ядер; иногда в фильтре используется одно ядро. Ядро — это обычная матрица чисел, называемых весами, которые “обучаются” (подстраиваются, если вам так удобнее) с целью поиска на изображениях определенных характеристик. Фильтр перемещается вдоль изображения и определяет, присутствует ли некоторая искомая характеристика в конкретной его части. Для получения ответа такого рода совершается операция свертки, которая является суммой произведений элементов фильтра и матрицы входных сигналов. С помощью операции свёртки мы получаем фичи, которые свёрточная сеть использует при обучении. Размер ядра сверточной нейронной сети определяет количество фич, которые будут объединены для получения новых фич на выходе.

![Операция свёртки](https://github.com/AxekA13/CNN-for-CIFAR-10/blob/master/Images/2d-covolutions.gif)

* Down sampling (maxpooling)

С целью ускорения процесса обучения и уменьшения потребления вычислительных ресурсов производят даунсемплинг исходных и/или промежуточных данных. Существует несколько способов сделать это, но конкретно в этой модели используется максимальное объединение (max pooling).

Операция максимального объединения заключается в том, что вдоль данных перемещается так называемое окно просеивания. Из пикселов, попадающих в его поле зрения, отбирается максимальный и перемещается в результирующую матрицу. Страйд для данного окна может быть отличным от единицы; все зависит от того, какого размера выходную матрицу нужно получить, и с какой степенью нужно “ужать” данные.Благодаря максимальному объединению уменьшается количество пикселов, что в свою очередь приводит к уменьшению количества выполняемых программой операций, и, соответственно, к экономии вычислительных ресурсов. Также благодаря ней нейронная сеть способна концентрироваться на действительно весомых характеристиках изображения, отбрасывая несущественные детали.Таким образом нейронная сеть становится менее подверженной переобучению, что часто становится весьма трудоемкой проблемой.

![Операция down sampling](https://github.com/AxekA13/CNN-for-CIFAR-10/blob/master/Images/MaxPool.gif)

## Параметры модели

Данная нейронная сеть была обучена на 50 эпопах с batch_size = 100, функцией потерь CrossEntropyLoss и оптимизатором Adam с learning rate = 0.01. Для борьбы с переобучением была использована L2-регуляризация с параметром alpha = 0.001. Для нормализации данных были использованы следующие значения mean=(0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010). В качестве функции активации была выбрана ReLU. Метрика - Accuracy. С количеством параметром и моделью можно ознакомиться ниже:

CNN:

(conv1): Sequential(
(0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
(1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): ReLU()
(3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
)

(conv2): Sequential(
(0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
(1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): ReLU()
(3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
)

(conv3): Sequential(
(0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))
(1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): ReLU()
(3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
)

(fc1): Linear(in_features=2048, out_features=256, bias=True)
(fc2): Linear(in_features=256, out_features=128, bias=True)
(fc3): Linear(in_features=128, out_features=10, bias=True)
)

Summary:

Layer (type) Output Shape Param #

Conv2d-1 [1, 32, 33, 33] 416

BatchNorm2d-2 [1, 32, 33, 33] 64

ReLU-3 [1, 32, 33, 33] 0

MaxPool2d-4 [1, 32, 16, 16] 0

Conv2d-5 [1, 64, 17, 17] 8,256

BatchNorm2d-6 [1, 64, 17, 17] 128

ReLU-7 [1, 64, 17, 17] 0

MaxPool2d-8 [1, 64, 8, 8] 0

Conv2d-9 [1, 128, 9, 9] 32,896

BatchNorm2d-10 [1, 128, 9, 9] 256

ReLU-11 [1, 128, 9, 9] 0

MaxPool2d-12 [1, 128, 4, 4] 0

Linear-13 [1, 256] 524,544

Linear-14 [1, 128] 32,896

Linear-15 [1, 10] 1,290


Total params: 600,746

Trainable params: 600,746

Non-trainable params: 0


Input size (MB): 0.01

Forward/backward pass size (MB): 1.57

Params size (MB): 2.29

Estimated Total Size (MB): 3.87

* Результаты 

Total train epochs Accuracy = 67.42

Total test epochs Accuracy = 69.26

Total train epochs Loss = 0.009072450283277033

Total test epochs Loss = 0.009456450032949449

### Результаты

Синий - тренировочная выборка,
Оранжевый - тестовая выборка

**Loss**

![Loss](https://github.com/AxekA13/CNN-for-CIFAR-10/blob/master/Images/Loss.png)

**Accuracy**

![Accuracy](https://github.com/AxekA13/CNN-for-CIFAR-10/blob/master/Images/Accuracy.png)
